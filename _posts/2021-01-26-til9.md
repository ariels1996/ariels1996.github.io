
# 여러 이미지 처리 신경망의 성공 이유

## AlexNet
+ 외적 요인
    - ImageNet이라는 대규모 사진 데이터
    - GPU를 사용한 병렬처리

+ 내적요인
    - 활성함수로 ReLU 사용
    - local response normalization 기법 적용
    - 여러 규제 기법 적용  
    데이터 augmentation 진행  
    완전 연결층에서 드롭아웃(dropout) 사용



## VGGNet

- 3*3의 작은 커널을 사용
- 신경망을 더욱 깊게 만듦 (컨볼루션 층이 Alex보다 2~3배 더 깊어짐)
- 작은 커널의 이점  
    큰 크기의 커널을 여러개의 작은 커널로 분해함으로써  
    매개변수의 수는 줄이고 신경망은 깊게 만들 수 있습니다. 


## GoogLeNet

- 인셉션 모듈  
    다양한 특징을 추출하기 위해 NIN의 구조를 확장하여 복수의 병렬적인 컨볼루션 층을 가집니다.
- NIN 구조  
    기존 컨볼루션 연산을 MLPConv 연산으로 대체 (커널 대신 MLP와 활성함수를 이용)  
    커널로 부분 정보를 가져오고 내적 대신 비선형 연산을 통해 feature를 추출하는 방식
- 완전 연결층 사용 지양  
    완전 연결층이 마지막 1개 밖에 없음 
- 보조분류기 사용  
    중간중간 분류기를 추가해서 오류 역전파 결과를 결합
    경사 소멸 문제를 완화시킵니다.  
 
## ResNet
- residual learning
    입력을 연산된 결과와 연결시켜 연결망이 학습한 부분을 더 신경쓰도록 만드는 기법 
    $y = \uptau(F(x) + x)$
- 깊은 신경망도 최적화가 가능 
    단순 구조의 변경으로 매개변수 수에 영향 X
- 전역 평균 풀링 사용
- batch normalization 적용

# 생성모델 

## 분별 모델과 생성 모델의 비교

|모델|학습 단계가 할 일| 예측 단계가 할 일| 지도 여부|
|---|---|---|---|
|분별 모델| $P(y \textpipe x)$ 추정 | $f: x -> y$ | 지도 학습|
|생성 모델| $P(x)$ 또는 $P(x \textpipe y)$, $P(x, y)$ 추정| $f: 씨앗 -> x$ 또는 $f: 씨앗, y -> x$, $f: 씨앗 -> x,y$ |비지도학습|

생성모델은 데이터를 추론하는데 집중합니다. 

## GAN의 핵심
생성기 G(generator)와 분별기 D(discriminator)의 대립 구도 


