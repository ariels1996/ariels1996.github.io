---
published: true
layout: single
title:  "Basic! 인공지능 수학 part 12: 교차엔트로피"
header:
  overlay_image: /images/unsplash-image-1.jpg
  caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
  actions:
    - label: "Learn more"
      url: "https://en.wikipedia.org/wiki/Bayesian_inference"
      
categories: [AI math_basic]
tags: [programmers, AI, math, statistics]
comments: true
---

Basic! 인공지능 수학 열 두 번째 시간으로 가설검정에 대해 알아보도록 합시다. 

&nbsp;

&nbsp;

## 엔트로피

&nbsp;

### 자기정보

![](/images/2020-12/crossentropy/1.png)  

![](/images/2020-12/crossentropy/2.png)  

&nbsp;

### 엔트로피 
&nbsp;  
엔트로피는 자기정보의 평균을 의미합니다. 

![](/images/2020-12/crossentropy/3.png)  

엔트로피는 데이터 압축에 많이 활용됩니다.  
자주 사용되는 아이템을 허프만 tree와 같이   
찾아내어 코드를 적게 사용하도록 만듭니다.  

![](/images/2020-12/crossentropy/4.png)  

&nbsp;

### 교차 엔트로피 
&nbsp;  
인공지능 학습에 필요한 손실함수에 교차 엔트로피를 사용합니다. 

* 확률분포 P와 Q
    
    ![](/images/2020-12/crossentropy/5.png)  

&nbsp;  
* 교차 엔트로피 $H(P, Q)$
    
    실제는 P, 실험으로 얻은 확률은 Q

    ![](/images/2020-12/crossentropy/6.png)  

    ![](/images/2020-12/crossentropy/7.png)  


    실제와 얻은 확률이 다르면 사용되는 정보량도 차이가 납니다. 

&nbsp;

### 분류 문제의 손실 함수 
&nbsp;  
![](/images/2020-12/crossentropy/8.png)  

![](/images/2020-12/crossentropy/9.png)  

&nbsp;  
차이를 확인하는 방법은 다음과 같습니다.  
기계학습에서 제곱합은 학습속도가 느린 문제가 있어  
교차 엔트로피를 사용합니다.

![](/images/2020-12/crossentropy/10.png)  

&nbsp;  
![](/images/2020-12/crossentropy/11.png)  

&nbsp;  
분류에서의 교차 엔트로피 예시는 다음과 같습니다. 

&nbsp;  
![](/images/2020-12/crossentropy/12.png)  

원하는 방향일수록 교차 엔트로피는 0에 가까워집니다. 





