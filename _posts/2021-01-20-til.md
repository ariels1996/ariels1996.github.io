---
published: true
layout: single
title:  "[TIL] 21/01/20"
header:
  overlay_image: /images/unsplash-image-1.jpg
  caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
  actions:
    - label: "Learn more"
      url: ""
      
categories: [TIL]
tags: [programmers]
comments: true
---

오늘의 TIL

&nbsp;

&nbsp;

# 퍼셉트론 목적함수의 정의 

퍼셉트론의 목적함수를 설계할 때는 아래와 같은 조건을 모두 만족시켜야 합니다.

+ $J(w) >= 0$이다.
+ $w$가 최적이면, 즉 모든 샘플을 맞히면 $J(w) = 0$이다.
+ 틀리는 샘플이 많은 $w$ 일수록 $J(w)$는 큰 값을 가진다. 

&nbsp;

# pytorch의 여러가지 연산들 

전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형 대수, 난수(random number) 등과 같은 100가지 이상의 Tensor 연산은 여기 <http://pytorch.org/docs/torch> 에 설명되어 있습니다.

&nbsp;

# 알고리즘 문제 풀이 재개

til도 진행하면서 하루에 한개씩 알고리즘 문제를 풀도록 하겠습니다.  
문제들은 프로그래머스에 수록되어 있는 문제를 위주로 진행할 예정입니다.

&nbsp;

# 은닉층의 깊이에 따른 변화 

공간을 접어가면서 최종 계층에서 직선으로 나눌 수 있도록 학습합니다.  
각 은닉층은 입력공간을 어디서 접을지를 지정합니다.  
지수적으로 많은 선형적인 영역 조각이 생긴다고 볼 수 있습니다.  
다층 퍼셉트론은 손실 함수를 여러 계층에 적용시키기 위해 오류 역전파를 이용합니다.  

&nbsp;

# 다층 퍼셉트론 시각화 
https://playground.tensorflow.org